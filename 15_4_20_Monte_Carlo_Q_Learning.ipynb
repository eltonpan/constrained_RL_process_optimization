{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sobol_seq in /opt/anaconda3/lib/python3.7/site-packages (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Authors: \n",
    "# E. Pan - Imperial College\n",
    "\n",
    "import pylab\n",
    "import numpy as np\n",
    "import scipy.integrate as scp\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import numpy.random as rnd\n",
    "from scipy.spatial.distance import cdist\n",
    "!pip install sobol_seq\n",
    "import sobol_seq\n",
    "from scipy.optimize import minimize\n",
    "eps  = np.finfo(float).eps\n",
    "import random\n",
    "import time\n",
    "matplotlib.rcParams['font.sans-serif'] = \"helvetica\"\n",
    "matplotlib.rcParams['font.family'] = \"helvetica\"\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from IPython.display import Audio, display # Import sound alert dependencies\n",
    "def Done():\n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "# Insert whatever audio file you want above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dyanmical System\n",
    "\n",
    "Here we have a dynamic system, where $x$ is biomas, $N$ is nitrogen source, and $F_{N_{in}}$ is an inflow rate.\n",
    "\n",
    "$$\\frac{\\text{d}x}{\\text{d}t}=\\mu~x~\\frac{N}{N+K_N}-\\mu_d~x$$\n",
    "\n",
    "$$\\frac{\\text{d}N}{\\text{d}t}=-Y_{Nx}x~\\mu~\\frac{N}{N+K_N}+F_{N_{in}}$$\n",
    "\n",
    "We wish to optimize at the final time $t_f$ the cost given by the biomass we can harves, minus a penalization for the nitrogen that was not consumed, the objective function is:\n",
    "\n",
    "$$f_{obj_1}=100x_{t_f}-N_{t_f}$$\n",
    "\n",
    "where $x_{t_f}$ and $N_{t_f}$ refer to the final biomass and nitrogen quantity. We can control $F_{N_{in}}\\in[0,7]$ with a precision of $0.5$ changing it $10$ times (equidistantly) from time $0$ to time $t_f$\n",
    "\n",
    "We can aditionally have an objective function that penalizes nitrogen source input:\n",
    "\n",
    "$$f_{obj_2}=100x_{t_f}-N_{t_f}-\\sum_{i=0}^{T}F_{N_{in}}^i$$\n",
    "\n",
    "where $T$ is the total number of time steps (inputs) and $F_{N_{in}}^i$ corresponds to the nitrate input at time-step $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming solutions\n",
    "\n",
    "To solve this problem, initially we should think of discretizing states (time is already discretized). This can be done for Biomass in $0.5$ intervals, and for Nitrate in $25$ intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Defining Environment ##############\n",
    "\n",
    "class Model_env: \n",
    "    \n",
    "    # --- initializing model --- #\n",
    "    def __init__(self, parameters, tf, modulus):\n",
    "        \n",
    "        # Object variable definitions\n",
    "        self.parameters       = parameters\n",
    "        self.tf, self.modulus = tf, modulus  # two column array [biomass nitrate]\n",
    "        \n",
    "    # --- dynamic model definition --- #    \n",
    "    # model takes state and action of previous time step and integrates -- definition of ODE system at time, t\n",
    "    def model(self, t, state):\n",
    "        # internal definitions\n",
    "        params = self.parameters\n",
    "        FCn   = self.u0\n",
    "                \n",
    "        # state vector\n",
    "        Cx  = state[0]\n",
    "        Cn  = state[1]\n",
    "        \n",
    "        # parameters\n",
    "        u_m  = params['u_m']; K_N  = params['K_N'];\n",
    "        u_d  = params['u_d']; Y_nx = params['Y_nx'];\n",
    "        \n",
    "        # algebraic equations\n",
    "        \n",
    "        # variable rate equations\n",
    "        dev_Cx  = u_m * Cx * Cn/(Cn+K_N) - u_d*Cx**2\n",
    "        dev_Cn  = - Y_nx * u_m * Cx * Cn/(Cn+K_N) + FCn\n",
    "        \n",
    "        return np.array([dev_Cx, dev_Cn],dtype='float64')\n",
    "    \n",
    "    def discrete_env(self, state):\n",
    "        # discretisation of the system, with introduction of stochasticity in terms of modulus\n",
    "        modulus = self.modulus\n",
    "        \n",
    "        # passing to arrays\n",
    "        modulus = np.array(modulus)    # eg. modulus = np.array([0.2, 20.]) basically what modulus does is it indicates the rounding of the conc of x and conc of nitrate\n",
    "        state   = np.array(state)  # eg. state = np.array([0.1,150.0]) first number is the conc of x and 2nd number is the conc of nitrate\n",
    "\n",
    "        resid = state % modulus \n",
    "        resid = resid/modulus # remember resid is now an array. resid is normalized with respect to the size of modulus \n",
    "        LB = resid.copy()\n",
    "        UB = 1 - resid # 1 minus resid because we are talking about normalized inverse length\n",
    "        draw = [0,0]\n",
    "        for i in range(state.shape[0]):\n",
    "            if LB[i] < UB[i]: #if lower bound distance is smaller (more likely to round down)\n",
    "                LB[i] = LB[i]**3 #make distance even closer\n",
    "                draw[i] = np.random.uniform(0,LB[i]+UB[i],1)\n",
    "            elif LB[i] > UB[i]: # else upper bound distance is smaller (more liekly to round up)\n",
    "                UB[i] = UB[i]**3\n",
    "                draw[i] = np.random.uniform(0,LB[i]+UB[i],1)\n",
    "            else:\n",
    "                draw[i] = np.random.uniform(0,1,1)        \n",
    "        for i in range(state.shape[0]):\n",
    "            if draw[i] < UB[i]: #introduce stochasticity w.r.t. rounding up or down\n",
    "                state[i] = state[i] - resid[i] * modulus[i] #rmb now resid is now a NORMALIZED array of 2 numbers so it has to be multiplied back to un-normalize residual #rounds down by substracting away the residual\n",
    "            else:\n",
    "                state[i] = state[i] - resid[i] * modulus[i] + modulus[i] #rounds up\n",
    "        \n",
    "        # fixes for representation \n",
    "        # Nitrate fix\n",
    "        if state[1] < 0:\n",
    "            state[1] = 0\n",
    "        elif state[0] < 0:\n",
    "            state[0] = 0\n",
    "        \n",
    "        # Biomass fix\n",
    "        f = str(self.modulus[0])\n",
    "        decimal = f[::-1].find('.')  \n",
    "        state[0] = np.round(state[0], decimal)\n",
    "        f1 = str(self.modulus[1])\n",
    "        decimal1 = f1[::-1].find('.')  \n",
    "        state[0] = np.round(state[0], decimal1)\n",
    "\n",
    "        if state[0] == eps:\n",
    "            state[0] = 0\n",
    "        if state[1] == eps:\n",
    "            state[1] = 0\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def simulation(self, x0, controls):\n",
    "        # internal definitions\n",
    "        model, tf     = self.model, self.tf\n",
    "        self.controls = controls\n",
    "        \n",
    "        # initialize simulation\n",
    "        current_state = x0\n",
    "        \n",
    "        # simulation #ONLY ONE STEP unlike the previous code shown above\n",
    "        self.u0   = controls[:]                       # control for this step\n",
    "        ode       = scp.ode(model)                      # define ode\n",
    "        ode.set_integrator('lsoda', nsteps=3000)        # define integrator\n",
    "        ode.set_initial_value(current_state, tf)         # set initial value\n",
    "        current_state = list(ode.integrate(ode.t + tf)) # integrate system\n",
    "        xt            = current_state                   # add current state Note: here we can add randomnes as: + RandomNormal noise\n",
    "        \n",
    "        return xt\n",
    "\n",
    "    def MDP_simulation(self, x0, controls): #simulate ONLY ONE STEP\n",
    "        xt          = self.simulation(x0, controls) #simulate\n",
    "        xt_discrete = self.discrete_env(xt) # make output state discrete\n",
    "        return xt_discrete\n",
    "\n",
    "    def reward(self, state):\n",
    "        reward = 100*state[-1][0] - state[-1][1]              # objective function 1\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating one Step of the dynamic system as a MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "# p        = {'u_m' : 0.0923*0.62, 'K_N' : 393.10, 'u_d' : 0.01, 'Y_nx' : 504.49} # predetermined parameters by design\n",
    "# tf       = 16.*24./10. # assuming 10 steps, we divide the whole horizon over 10 for one step\n",
    "# x0       = np.array([0.2,700.0]) # initial state\n",
    "# modulus  = [0.1, 60.] # basically what modulus does is it indicates the rounding of the conc of x and conc of nitrate\n",
    "# u0       = np.array([7.]) #this is your CONTROL (rmb here it's only ONE STEP)\n",
    "\n",
    "# MDP_BioEnv = Model_env(p, tf, modulus)\n",
    "# MDP_BioEnv.MDP_simulation(x0, u0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating multiple steps of the dynamic system as a MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d1de4feb403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFCn_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mMDP_BioEnv\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mModel_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodulus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mu0\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFCn_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx0\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mMDP_BioEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMDP_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#simulate one step, and update current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "steps_      = 10\n",
    "FCn_0       = [np.sin(i/6.5)*2+5. for i in range(steps_)]\n",
    "x0          = np.array([0.2,150]) # initial state\n",
    "tf          = 16.*24./10.\n",
    "x_list      = np.zeros((2,steps_+1)) #initialize state as 2D array where the 2 rows refer to conc of x and N.\n",
    "t_list      = np.zeros((1,steps_+1)) #initialize time as 1D array\n",
    "x_list[:,0] = x0\n",
    "t_list[0]   = tf\n",
    "\n",
    "for s in range(len(FCn_0)):\n",
    "    MDP_BioEnv    = Model_env(p, tf, modulus)\n",
    "    u0            = np.array([FCn_0[s]])\n",
    "    x0            = MDP_BioEnv.MDP_simulation(x0, u0) #simulate one step, and update current state \n",
    "    tf            = tf + 16.*24./10. #increment time\n",
    "    x_list[:,s+1] = x0 #update state memory\n",
    "    t_list[:,s+1] = tf #update time memory\n",
    "\n",
    "for i in range(x_list.shape[0]):\n",
    "    plt.plot(t_list[0,:],x_list[i,:])\n",
    "    plt.ylabel('state')\n",
    "    plt.xlabel('time')\n",
    "    plt.show()\n",
    "plt.step(t_list[0,:-1],FCn_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.2,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,\n",
       "          0. ,   0. ],\n",
       "       [150. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,\n",
       "          0. ,   0. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and describe system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discrete_states: 319\n",
      "Shape of value table: 29 x 11\n",
      "Number of possible actions: 8\n",
      "Number of possible times: 11\n"
     ]
    }
   ],
   "source": [
    "p        = {'u_m' : 0.0923*0.62, 'K_N' : 393.10, 'u_d' : 0.01, 'Y_nx' : 504.49} # predetermined parameters by design\n",
    "tf       = 16.*24./10. # assuming 10 steps, we divide the whole horizon over 10 for one step\n",
    "modulus  = [0.20, 25.] # basically what modulus does is it indicates the rounding of the conc of x and conc of nitrate\n",
    "\n",
    "Number_of_possible_x      = int(2.0/modulus[0]+1) #assumed max x value is 1.6\n",
    "Number_of_possible_N      = int(700/modulus[1]+1) #assumed max N value is 400\n",
    "Number_of_discrete_states = int(Number_of_possible_x * Number_of_possible_N)\n",
    "max_increase_N = 7 # Maximum increase in N per time step\n",
    "increment_N    = 1 # Spacing between increase in N\n",
    "Number_of_possible_actions = int(max_increase_N/increment_N + 1)\n",
    "Number_of_possible_times   = 11\n",
    "\n",
    "MDP_BioEnv = Model_env(p, tf, modulus) # Initialize system\n",
    "\n",
    "print('Number of discrete_states:', Number_of_discrete_states)\n",
    "print('Shape of value table:', Number_of_possible_N , 'x', Number_of_possible_x)\n",
    "print('Number of possible actions:', Number_of_possible_actions)\n",
    "print('Number of possible times:', Number_of_possible_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to map action to actual increase in N\n",
    "action_ID = [x for x in range(Number_of_possible_actions)]\n",
    "increase_in_N = [x for x in np.arange(0,max_increase_N+increment_N,increment_N)]\n",
    "action_ID_to_increase_in_N = dict(zip(action_ID,increase_in_N))\n",
    "action_ID_to_increase_in_N #this dictionary maps action id to actual action itself (increase in N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(state, action): # state can be described by tuple(x (algae conc), N (nitrate conc), time (in hours)), action can be described by FN âˆˆ[0,7]\n",
    "    '''arguments\n",
    "       state: (x, N, t) tuple \n",
    "       action: int (0-14)\n",
    "    \n",
    "       outputs \n",
    "       new state: (x, N, t) tuple\n",
    "       reward: int \n",
    "       '''\n",
    "    state = np.array(state) \n",
    "    action = [action_ID_to_increase_in_N[action]] #assign action according to dictionary defined above\n",
    "    \n",
    "    if (abs(state[2] - 16.*24.) < 0.1): #check if terminal state is reached\n",
    "        reward = (100 * state[0] - state[1])   #give reward when we LEAVE terminal state\n",
    "        state[2]      += 16.*24./10. #increment time\n",
    "        state_evolved = MDP_BioEnv.MDP_simulation(state[0:2], action) #evolve the system using ODE\n",
    "        state_evolved = [round(state_evolved[0],1),round(state_evolved[1],1)]\n",
    "        new_state = np.append(state_evolved,round(state[2],2)) # append time\n",
    "        \n",
    "    elif (state[2] > 16.*24.): #check if time is exceeded\n",
    "        new_state = state #loop back to itself\n",
    "        reward = 0 #and given zero reward    \n",
    "\n",
    "    else: #else evolve the system and assign zero reward\n",
    "        state[2]      += 16.*24./10. #increment time\n",
    "        state_evolved = MDP_BioEnv.MDP_simulation(state[0:2], action) #evolve the system using ODE\n",
    "        state_evolved = [round(state_evolved[0],1),round(state_evolved[1],1)]\n",
    "        new_state = np.append(state_evolved,round(state[2],2)) # append time\n",
    "        reward    = 0 # if terminal step not reached, reward = 0\n",
    "\n",
    "    return tuple(new_state), reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.4, 75.0, 38.4), 0)\n",
      "((0.4, 125.0, 38.4), 0)\n",
      "((0.4, 150.0, 38.4), 0)\n",
      "((0.4, 175.0, 38.4), 0)\n",
      "((0.4, 200.0, 38.4), 0)\n",
      "((0.4, 225.0, 38.4), 0)\n",
      "((0.4, 275.0, 38.4), 0)\n",
      "((0.4, 300.0, 38.4), 0)\n"
     ]
    }
   ],
   "source": [
    "# Test transition function\n",
    "for i in range(Number_of_possible_actions):\n",
    "    print(transition((0.2,150,0),i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate 1 episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current policy: [0, 6, 3, 4, 2, 2, 1, 5, 2, 0, 5]\n",
      "Concentration of x: [0.2, 0.4, 0.6, 0.8, 0.8, 0.8, 0.8, 0.6, 0.6, 0.8, 0.6, 0.6]\n",
      "Concentration of N: [150, 75.0, 175.0, 100.0, 75.0, 50.0, 50.0, 25.0, 100.0, 50.0, 0.0, 100.0]\n",
      "\n",
      "Episode: [[(0.2, 150, 0), 0, 0], [(0.4, 75.0, 38.4), 6, 0], [(0.6, 175.0, 76.8), 3, 0], [(0.8, 100.0, 115.2), 4, 0], [(0.8, 75.0, 153.6), 2, 0], [(0.8, 50.0, 192.0), 2, 0], [(0.8, 50.0, 230.4), 1, 0], [(0.6, 25.0, 268.8), 5, 0], [(0.6, 100.0, 307.2), 2, 0], [(0.8, 50.0, 345.6), 0, 0], [(0.6, 0.0, 384.0), 5, 60.0]]\n",
      "Score: 60.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXBU55nv8e+jHe2gDbQ2mNWA2QRIkNhkHG/EwXYYY1tGYibj8Z1KzSSeyaRmnLp3puIaj1NO7uXOzUx5rlM1N0gYGzsOJo5jO8SJHce0EAKMAbMYg1oLWhHa0C699w+1bJmttXT36dP9fKood/fpPufxy9FPh3NOv48YY1BKKWVfYVYXoJRSamo0yJVSyuY0yJVSyuY0yJVSyuY0yJVSyuYi/L3B1NRU43A4/L1ZpZSytUOHDrUYY9KutczvQe5wOKisrPT3ZpVSytZExHW9ZXpqRSmlbE6DXCmlbE6DXCmlbM7v58iVUspKAwMD1NbW0tvba3Up1xQTE0N2djaRkZHj/owGuVIqpNTW1pKQkIDD4UBErC7nC4wxXLx4kdraWmbPnj3uz93w1IqMeE5EXCJSLiLZVyz/poicFJGzIvKdSdaulFJ+09vbS0pKSsCFOICIkJKSMuF/LXg6R74JSAMcwHbg6TEbjAX+CVgF3AJ8R0SueY+jUkoFkkAM8VGTqc3TqZWNwA5jjBGRPcCzY5aN/hKIHfO8b8IVKL+rb+9h98Eahod1CmNvyEiKoWhNbkCHgx00d/bx3plmNq/M0rGcIE9BngvUAhhj+kUkXETCjDHDxpguEfk5UO1+b6kxpuNaKxGRx4HHAXJzc71UupqsH799hlcP16I/K1M3Op3/gowE8h0zrC3G5n789ml2V9aQOyOWNbN1LCfCU5AbYHDM80FjzDCAiNwM3A1ku9/3roisMsYcumolxjwPPA+Qn5+vh4EWar3cz+sfXWBrQS7/cv9Sq8uxve7+Qdb+6zuUOl0a5FPQ1t3P3qN1AJQ6qzTIJ8jTOfI6IBNARCKBsWfglwLvGGNajTGXgLeAxT6pUnnN7oM19A8OU1LosLqUoBAbFcGDq3J483g9TZ2BeTubHbxSWUvvwDC3zk/jreMNNHUE71g+8cQTPPHEEwB861vf4tlnn/XwCc88HZG/ARQBb7v/u2/MshPAP7gveg4C64GdU65I+czQsGFnuYuCOTOYn5FgdTlBo7gwj//64DwvVdTw7dvnWV2O7QwPG8rKXax2TOepTYvZ8ON32VVRzRNfne/zbf/g9RN8fOGaZ4Qn7ebMRP7569c/pn3qqadYsmQJ69ev5w9/+AP/9m//NuVtejoi3wsMiMg54JvAD0TkGRF5wBhzHPgv4DDwEfCaMebYlCtSPvO7U03UtfXo0biXzU6N49b5abxwwMXA0LDV5djOe2eaqW7tpqTQgSM1jg0L0th1oDpoxzIxMZGnn36ahx56iO3bt0/oiz/Xc8MjcjPSmfmxK15+cszyfwf+fcpVKL8odVYxMzGGO27OsLqUoLOtMI+/2FHJvo8b2bh0ltXl2Eqps4q0hGjuWjwTgJLCPL75s0rePtHAvbdk+nTbNzpy9qXGxkZiYmJoamryyvp0rpUQca65i/c/aaFobS6R4frX7m0bFqSTPX0aO/ZXWV2KrbguXubdM80UrcklKmJkv7xtfjq5M2Ip3X/dWVttrb6+np/85Cfs27eP73//+3R2dk55nfoTHSLKyl1EhgsPr8mxupSgFB4mFBfkceB8K6cbpv6DGSp2lrsIF6Fo7ee3JYeHCVsLcqmoauVkvXfPXweC733ve3z7299m/fr1fOMb3+Cpp56a8jo1yEPA5b5Bfl5Zyz1LZpGeEGN1OUFrS34O0RFhlDqrrC7FFnr6h9h9sIa7lswkI/GL++XnYxl8R+U7d+7ku9/9LgDbt2/nRz/60ZTXqUEeAl77sI7OvkG2rcuzupSgNj0uik3LMtlzpI6O3gGrywl4vzxaR0fvICUFV++XybFR3Lc8k9eO1NHeo2PpiQZ5kDPGULrfxc2zElmZO93qcoJeSaGD7v4hXj1Ua3UpAc0Yw479LhbOTLjul39KCh30DAzxcx1LjzTIg1zF+VZON3aybV2ezl/hB0uzk1iRm0yZ06Vz2dzA4epLfFzfQXHh9ffLJVlJrMxNZme598fSmMD9u5lMbRrkQa603EXStEg2LcuyupSQUVKYx7mWy3zwaYvVpQSsHftdJMREcP/yG++X29Y5ON9ymffPem8sY2JiuHjxYkCG+eh85DExE7uWpY0lglhjRy9vH2/gz9c7mBYVbnU5IWPj0ln8y69OUup08eV5OrPzlZo6e3nzeD1bC/KIi75xBN29ZCap8VGUOau4bb53xjI7O5va2lqam5u9sj5vG+0QNBEa5EFs14Fqhoxh6zUuJinfiY4I5+E1OTz37qfUXuome3qs5w+FkJcqahgYMhSPY7+MjgjnkTW5/Pvvz1LT2k3OjKmPZWRk5IS679iBnloJUv2Dw+yqqGbD/DTyUuKsLifkPLp2JKReOFDt4Z2hZWBomF0HqvnyvFTmpMWP6zNFa3MJE2HngeC7FdFbNMiD1NsnGmju7NN5VSySmTyNO27O4KWKanoHhqwuJ2Ds+7iRho5etk1gv5yVNI07b85g98EaHcvr0CAPUqXOKnJnxHrtvKKauG2FDi51D/DGR/VWlxIwSp1VZCVP4ysL0yf0ueLCPNq6B3j96AXfFGZzGuRB6OMLHRysukRxQR5hYXrLoVUKb0phbnq8ftPT7XRDJ+XnWikuzCN8gvtl4ZwU5qXHU+p0BeTdJlbTIA9CZeVVxESG8WD+xK58K+8SEUoK8zha286HNW1Wl2O5svIqoiLC2JI/8fl+RsfyWJ2O5bVokAeZ9u4BXjtygfuWZZEcG2V1OSHvgRVZxEWFh/xReUfvAL84XMemZZnMiJvcfvnAymzioyOCcv6VqdIgDzKvHKqhZ2CI4kK95TAQJMREsnlVNr/6qJ6LXX1Wl2OZXxyqpbt/iJIp7Jfx0RFsXpnFGx/V0xLCY3ktGuRBZNjdym1V3nSWZCVZXY5yKy7Io39wmN2VNVaXYgljDKXlLpbnJHNLdvKU1lVc6KB/aJjdB0NzLK9HgzyI/OGTZqoudk/pqEd537yMBNbdlMIL5dUMheD8Kx+cvci55ste2S/npsezfm4KL5S7GAzSVnCToUEeRMqcLlLjo7lnibYaCzQlhXnUtfXwzslGq0vxux3OKlLiorzWAq+k0MGF9l5+e9I7bdKCgQZ5kKhp7eZ3p5soWpPzWcssFTi+uiiDWUkxlJWH1oW62kvdvHOykYdW5xAT6Z35fm5fmE5mUgxl5VVeWV8w0J/4ILGz3EWYCEVr9bRKIIoID+PRtbm8/0kLnzZ3WV2O34xOUfCoF+f7iQgP49GCPD44e5GzTdpWDzTIg0LvwBC7K2u4a3EGM5O0lVugenhNLlHhYZSFyO1zvQMjrdy+uiiDrORpXl33w6tzQmosPdEgDwK/PHqBtu4BigscVpeibiA1PpqNS2fy6qFaLvcNWl2Oz73xUT2tl/t9Mt9PSnw0994yi1cP19EVAmPpiQa5zRljKHVWMT8jnoI5126ZpQJHyToHnX2D7DlSZ3UpPlda7mJOWhzr56b4ZP3FhXl09Q2y57C2grthkMuI50TEJSLlIpI9ZtnXReTUmD/VIvJ3vi9ZjXWkpo3jdR0UFzq0lZsNrMhJZklWIqXOqqCeM+RoTRtHa9ooKfBdi8GR+9KT2KHzr3g8It8EpAEOYDvw9OgCY8zrxpiFxpiFwHKgBijzUZ3qOkr3V5EQHcE3VmgrNzsYmTPEwZnGLg6cb7W6HJ8pdbqIiwpn8yrfzfcjIhQX5HG2qQvnuYs+244deAryjcAOM/Lrbg+w4Trv+3tgtzEmMHsnBanmzj5+fayBzauyPbbMUoFj07JMkmMjg3b+ldbL/bz+0QUeWJlFQkykT7f19WWZTI+NpHR/aF/09BTkuUAtgDGmHwgXkS98RkTigBLgp9dbiYg8LiKVIlIZqH3y7Gj3wWr6h4a1lZvNxESG81B+Dm+faKShvdfqcrxu98Ea+geH/dLUJCYynC2rc9h3spELbT0+316g8hTkBhh7SXjQGHPl92IfZuRo/LqjaIx53hiTb4zJT0vTRgfeMDg0zAsHqvnS3FTmpo+vZZYKHFsL8hg2hl1B1r5syD3fT8GcGczPSPDLNreuHR3L0G2r5ynI64BMABGJBK51+PDnwM+9XJfy4LcnG6lv79V5VWwqZ0Ysf7IgnV0VI0evweJ3p5qoa+uZUCu3qcqZEcvtC9N56WA1fYOh2QrOU5C/ARS5HxcB+8YuFJFYIMcYc9QHtakbKHW6yEqexu2LMqwuRU1ScWEeLV19vHk8eFrBlTqrmJkYwx03+3e/LCl00NLVz5vHGvy63UDhKcj3AgMicg74JvADEXlGRB5wL18NfOTLAtXVPmnsZP+nF3m0IHfCLbNU4Lh1XhqOlNig+Xbip81dvP9JC4+uzSUi3L9fUfnS3FRmp8YF7QVkT2442mbEY8aYOcaY24wxLcaYJ40xe9zL3zPGfN0/papRZeUuosLDeGgSLbNU4AgLE7YW5FHpusSJC+1WlzNlZU4XkeHCw2ty/b7tsLCRWxEPV7dxvM7+YzlR+s1Om+nsHeDVQ7Xcu2wWKfHRVpejpujBVTlMiwy3/VH55b5BXj1Uy8als0hLsGa/3Lwqm9gQbaunQW4ze47Ucbl/yC+3dinfS4qN5P4Vmbz2YR3t3QNWlzNpe47U0dk3aOnF96Rpkdy/Iou9H17g0uV+y+qwgga5jYzMq+JiWXYSy3Om1jJLBY7iAge9A8O8csie7cuMMZQ5XSzOTGRl7nRLaykpzKNv0L5jOVka5Dbi/PQiZ5u6KNaj8aByc2Yiqx3TKSt3MWzDVnAHzrdyurGTkkLfzasyXgtnJrJm9gzKyl0h1VZPg9xGdjirmB4byb23aCu3YFNS6MB1sZv3PrHfN5/LnC6SpkWyaVlgzPezrdBBTWsP750JnVZwGuQ2UdfWw76PG3loda7XWmapwHHX4pmkJURTur/K6lImpKG9l7dONLAlP5tpUYGxX965OIOMxGh2hND8KxrkNjH6Ve5H1/r/1i7le1ERYRStyeXdM824Ll62upxx21VRzbAxATXfT2R4GEVr8njvTDNVLfYZy6nQILeBvsEhXqqo4U8WZpAzI9bqcpSPFK3NJVyEnTZp0Nw/OMyuA9VsmJ9GXkqc1eV8wSNrcogIk5Bpdq1BbgO/PlbPxcv9bFsXOEc9yvsyEmO4a8lMXq6spac/8OcMeetEAy1dfZSsc1hdylXSE2O4Z+ksXqmsobs/+FvBaZDbQKnTxZzUONbflGp1KcrHSgryaO8Z4JdHA78VXOn+KvJSYrltXmDOaFpSmEdH7yB7P7xgdSk+p0Ee4I7VtnOkuo3iwjzCdF6VoLdm9gwWzkxgx/7Abl924kI7la5LFBcE7n6ZnzedRbMSKQ2BVnAa5AGu1FlFrI9bZqnAISIUF+bxcX0Hh6svWV3OdZU5XcREhvHgqsCd72ekrV4eJ+s7qHQF7lh6gwZ5ALt0uZ9fHr3AAyuySPRxyywVOO5fnkVCTASlATr/Snv3AK99WMf9y7NIig3s/fK+5ZkkBvBYeosGeQB7ubKGPj+1zFKBIy46gj9dlc2vj9XT3NlndTlXeeVQDb0DwxTboKlJbFQED+bn8Oaxepo6gq+t3igN8gA1NGwoK3exdvYMFsz0T8ssFTiKC/IYGDK8VBFY7cuG3ftlft50FmcmWV3OuBQX5DE4bHixInjnX9EgD1Dvnm6i9lKPHo2HqDlp8Xx5XiovHKhmcChwWsG990kzrovdtjgaH+VIjeO2+Wm8cMDFQACNpTdpkAeoHU4XGYnR3LlYW7mFqm2FDho6etn3caPVpXymzOkiNT6ae5bYa76fbevyaOrs4zcnAmcsvUmDPACdb7nMH840U7Qmj0g/t8xSgeMrC9PJSp7GDmeV1aUAUH2xm9+fbqJoTQ5REfbaL2+bn07OjMAZS2+z199GiBhtmfXI2sC9tUv5XnjYyK2I5edaOdPYaXU57DzgIkyEorX2Oa0yKtzdCq7ifCunGjqsLsfrNMgDTHf/IK8cquHuJbNIT4ixuhxlsS35I0e/Vrcv6+kfYvfBGu5anMHMJHvul1vyc4iOCAvKWxE1yAPMa0cu0Nk7yDYbXUxSvjMjLopNyzL5xeE6OnqtawX3+tELtPcM2Prie3JsFPctz2TP4Trae+zbVu9aNMgDyEgrtyoWzUpkVZ61LbNU4CgpzKO7f4hfHKq1ZPvGGHY4q5ifEc/a2TMsqcFbSgod9AwM8apFY+krGuQB5GDVJU41dLItAFpmqcBxS3Yyy3OSKS23Zs6Qw9VtnLjQQUmhw/b75ZKsJFbmJrPTpm31rkeDPICUOqtIjIngvuWB0TJLBY6SwjzONV/mg7MX/b7tUmcVCdERPLAiOPbLkkIH51ou88ezLVaX4jUeg1xGPCciLhEpF5HsK5YXisgJETkrIv/ku1KDW1NHL28db2BLfk7AtMxSgWPj0lmkxEX5/aJnc2cfvz5Wz+ZV2cRFR/h1275yz9KZpMZHBdVFz/EckW8C0gAHsB14enSBiIQBPwW2AIuBh0REr9JNwq6KagaHA6tllgocMZHhPLQ6h9+ebKSurcdv232popqBIWOrb3J6Eh0RzsOrc3nnVCM1rd1Wl+MV4/kVuxHYYYwxIrIHeHbMsqXAeWPMCQAR2QS0er/M4DYw5G6ZtSANR2pgtcxSgePRgjz+871P+faLR5jjp/3kd6ea+PK8VG5Ki/fL9vylaG0uz733Kd956Yhf/98eWJnFOh80iBlPkOcCtQDGmH4RCReRMGPMMDAX6BeRNxk5Yv8vY8yPrlyBiDwOPA6Qm6vNg6/09okGmjr7+GEQHfUo78tKnsa2dQ7ePt5AvZ+OymOjw/nWhrl+2ZY/ZSZP48/WOXjzWD0N7f6bFXHd3BSfrFc8XQUXkV8D/2CMOeZ+XmWMcbgfbwV+CKwBOoA/AH9ljKm43vry8/NNZWWld6oPElv+00lDRy+///sNhAdotxWllLVE5JAxJv9ay8ZzjrwOyHSvKBIY++vrEvCBMeaCMaYL2AcsmGK9IeVkfQcVVa1sLcjVEFdKTcp4gvwNoMj9uIiRsB7lBJaLyHR3yH8JOOTdEoNbqdNFdEQYW/J1XhWl1OSM5xz5XuBeETkH1ACbReQZoMIYs0dE/gH4o/u9zxtjPvZRrUGnvWeA147Ucd/yTJJjo6wuRyllUx6D3IycRH/sipefHLP8NeA1L9cVEn5+qJaegSFbz1+hlLKefrPTIsPDhp3lLlbmJrMkyx4ts5RSgUmD3CLvn23hfMtltq1zWF2KUsrmNMgtUuasIjU+iruXzLS6FKWUzWmQW6CmtZt3TjXxyJpcoiN0XhWl1NRokFvg85ZZ+i1XpdTUaZD7We/ASMusO2/OYFbSNKvLUUoFAQ1yP3v96AXaugeCajY5pZS1NMj9aKSVm4t56fEUzvHN5DlKqdCjQe5HH9a0cayunRJt5aaU8iINcj8qdbqIj47ggZXZnt+slFLjpEHuJy1dfbzxUT2bV2YRHyQts5RSgUGD3E92H6yhf2iYYp1XRSnlZRrkfjA4NMzOchfr56YwNz24WmYppaynQe4Hvz3ZRH17r85yqJTyCQ1yPyh1VpGZFMPtC9OtLkUpFYQ0yH3sbFMn+z+9yKMFeUSE63ArpbxPk8XHSp0uosLDeHi1tnJTSvmGBrkPdfYO8OqhWu69ZRYp8dFWl6OUClIa5D6050gdl/uHKNHmEUopH9Ig95HReVVuyU5ieU6y1eUopYKYBrmPOD+9yNmmLr3lUCnlcxrkPlLqdDE9NpJ7b5lldSlKqSCnQe4DF9p6+M3HDTy0OpeYSG3lppTyLQ1yH9h1oBoDPKqt3JRSfnDDIJcRz4mIS0TKRST7iuX/ISKnReSU+0+Ub8sNfH2DQ7xYUc3tCzPImRFrdTlKqRDgaT7VTUAa4AC2AE8D28YsXwAsMcYM+KQ6G3rzWAMXL/dToq3clFJ+4unUykZghzHGAHuADVcsj9YQ/6IdzirmpMbxpbmpVpeilAoRnoI8F6gFMMb0A+EiEgYjp10Ah4h8ICInROTx661ERB4XkUoRqWxubvZW7QHnWG07R6rb2FqQR1iYtnJTSvmHpyA3wOCY54PGmGH341jgReBrwK3AX4vIimuuxJjnjTH5xpj8tLS0qdYcsEqdVcRGhbN5lbZyU0r5j6cgrwMyAUQkEugds6wf+CdjTJsx5iLwFrDYJ1XawKXL/fzy6AXuX5FF0rRIq8tRSoUQT0H+BlDkflwE7BuzbBXwexGJFJFY4E+ASu+XaA8vV9bQNzisFzmVUn7n6a6VvcC9InIOqAE2i8gzQIUxZo+I/B44A1wG/sMYc8q35QamoWHDzgMu1syewcKZiVaXo5QKMTcMcvfdKo9d8fKTY5Z/H/i+D+qylXdPN1HT2sM/3r3I6lKUUiFIv9npBaVOFxmJ0dy5OMPqUpRSIUiDfIrOt1zmvTPNFK3JI1JbuSmlLKDJM0U7y11EhAmPrNFWbkopa2iQT0F3/yAvV9Zwz9JZpCfGWF2OUipEaZBPwd4PL9DZO6i3HCqlLKVBPknGGHbsr2LRrETy86ZbXY5SKoRpkE9SpesSpxo6KSnMY2TaGaWUsoYG+STt2F9FYkwE9y3PtLoUpVSI0yCfhKaOXt463sCD+TnERnn6cqxSSvmWBvkk7KqoZnDYUFygFzmVUtbTIJ+ggaFhdh2o5rb5aThS46wuRymlNMgn6u0TDTR19rFtnR6NK6UCgwb5BJU6XeTMmMZt89OtLkUppQAN8gk51dBBxflWigvyCNdWbkqpAKFBPgGlThfREWFsydd5VZRSgUODfJzaewbYc7iO+5ZnkhwbZXU5Sin1GQ3ycXr1UC09A0OUFDqsLkUppb5Ag3wchocNZeUuVuYmsyQryepylFLqCzTIx+GPZ1s433JZj8aVUgFJg3wcSp1VpMZHcc/SmVaXopRSV9Eg96CmtZt3TjXx8OpcoiPCrS5HKaWuokHuwc4DLsJEKFqba3UpSil1TRrkN9A7MMTugzXcsSiDzORpVpejlFLXpEF+A68fvUBb9wAlOq+KUiqA3TDIZcRzIuISkXIRyb7O+34kIj/0TYnWMMZQ6nQxLz2ewjkpVpejlFLX5emIfBOQBjiA7cDTV75BRPKBbV6vzGIf1rRxrK5dW7kppQKepyDfCOwwxhhgD7Bh7EIRiQSeBX7kk+osVOp0ER8dwQMrr/mPEKWUChiegjwXqAUwxvQD4SIy9jP/CJQCzTdaiYg8LiKVIlLZ3HzDtwaElq4+3vionm+szCI+Wlu5KaUCm6cgN8DgmOeDxphhABFZBBQYY37maSPGmOeNMfnGmPy0tLRJF+svuw/W0D80TEmhXuRUSgU+T4ebdUAmcMx9GqV3zLJbgZtF5BSQBESJSLsx5hnflOofg0PDvFDuYv3cFOamJ1hdjlJKeeTpiPwNoMj9uAjYN7rAGPN/jTGzjTELgSeBn9o9xAF+e7KJC+29FBc4rC5FKaXGxVOQ7wUGROQc8E3gByLyjIg84PvSrFFWXkVmUgxfXaSt3JRS9nDDUyvuu1Ueu+LlJ6/xvp95sSbLnG3q5IOzF/neXQuICNfvSiml7EHTaowyp4uo8DAeWq2t3JRS9qFB7tbVN8irh+v42i2zSI2PtrocpZQaNw1ytz2Ha+nqG9RbDpVStqNBzufzqizNSmJ5TrLV5Sil1IRokAPOcxf5pKlL51VRStmSBjkjFzmTYyP5+rJMq0tRSqkJC/kgr2/v4TcfN/LQ6hxiIrWVm1LKfkI+yHcdqGbYGLau1YucSil7Cukg7xsc4sWKam5fmE7OjFiry1FKqUkJ6SB/63gDLV39FBc6rC5FKaUmLaSDfMf+KmanxvHlualWl6KUUpMWskF+vK6dw9VtbC3IIyxMbzlUStlXyAZ5qbOKaZHh/OkqbeWmlLK3kAzytu5+9n54gftXZJE0LdLqcpRSakpCMshfrqyhb1BbuSmlgkPIBfnQsGFneTVrHDNYNCvR6nKUUmrKQi7I3zvTRHVrNyXr9GhcKRUcQi7IS50u0hOiuWvxTKtLUUoprwipIK9qucy7p5spWptLpLZyU0oFiZBKs53lLiLChKI1uVaXopRSXhMyQd7TP8TLlTXcvWQm6YkxVpejlFJeEzJBvvfDOjp6BynReVWUUkEmJILcGMMOp4uFMxNY7ZhudTlKKeVVIRHkh1yXOFnfQUmhQ1u5KaWCjscglxHPiYhLRMpFJPuK5c+KyGn3n22+K3XydjhdJMREcP8KbeWmlAo+4zki3wSkAQ5gO/D06AIRuQ1YBiwCvgT8UALskLepo5c3j9Xz4KocYqMirC5HKaW8bjxBvhHYYYwxwB5gw5hlNcD3jDHDQALQ435fwHixoobBYUOxzquilApS4wnyXKAWwBjTD4SLSJj7+TljzEci8r+BT4Bd11qBiDwuIpUiUtnc3Oyl0j0bGBpmV4WLW+enMTs1zm/bVUopfxpPkBtgcMzzQfcR+OdvMOYJIAcoFpHZV63AmOeNMfnGmPy0tLQpFTwRvznRSGNHH9v0aFwpFcTGE+R1QCaAiEQCvaMLROTPRORrAMaYC8ABIGA6NZQ6q8iePo0NC9KtLkUppXxmPEH+BlDkflwE7BuzrAN43H1nSypwC3DCuyVOzqmGDg6cb6W4II9wbeWmlApi47mNYy9wr4icY+Ti5mYReQaocC+7i5Hz473A940xrb4qdiLKnC6iI8LYkp9jdSlKKeVTHoPcfRfKY1e8/OSYx//NqxV5QUfvAHuO1LFpWSbT46KsLkcppXwqKL/Z+eqhWrr7h3ReFaVUSAi6IB8eNpQ5XazITWZpdpLV5SillM8FXZB/8GkL51oua2NlpVTICLog37HfRUpcFBuXzrK6FKWU8ougCvKa1m5+d6qRh9fkEB0RbnU5SinlF0EV5C8cqAbg0aHkPzQAAAZBSURBVLV6WkUpFTqCJsh7B4bYfbCaO27OIDN5mtXlKKWU3wRNkP/qo3oudQ+wTW85VEqFmKAJ8jJnFXPT4ym8KcXqUpRSyq+CIsg/rGnjaG07JYV52spNKRVygiLIS51VxEWF88CKLKtLUUopv7N9kF/s6uNXR+vZvCqbhJhIq8tRSim/s32Q766soX9omOICveVQKRWabB3kQ8OGF8qrWXdTCvMyEqwuRymlLGHrIH/nZCN1bT06r4pSKqTZOshLnS5mJcXw1UUZVpeilFKWsW2Qn23q4o9nW3h0bS4R4bb931BKqSmzbQLuLHcRFR7Gw2tyrS5FKaUsZcsg7+ob5NVDtWxcOpPU+Giry1FKKUvZMsj3HKmjs2+QYp1XRSml7BfkxhjKnFUsyUpkZW6y1eUopZTlbBfk5edaOdPYRUmBQ+dVUUopbBjkZeVVJMdGsml5ptWlKKVUQLBVkNe39/D2iUa25OcQE6mt3JRSCsYR5DLiORFxiUi5iGRfsfyvRaRaRE6JyLd8Vyq8eKCaYWPYqq3clFLqM+M5It8EpAEOYDvw9OgCEUkH/g64BcgH/kZEfHLOo39wmF0VNXxlQTq5KbG+2IRSStnSeIJ8I7DDGGOAPcCGMcvygJeNMW3GmC7gBHCT16sE3jxeT0tXn86ropRSVxhPkOcCtQDGmH4gXETC3M8PGmP+EUBElgPrgONXrkBEHheRShGpbG5unlSh8dER3HFzBrfOS5vU55VSKliNJ8gNMDjm+aAxZnjsG0TkO8Cvgb8wxly6agXGPG+MyTfG5KelTS6Ib1+UwU9L8gkL01sOlVJqrIhxvKcOyASOiUgk0Dt2oYg8D8wGVhtj6rxfolJKqRsZzxH5G0CR+3ERsG90gYisBFYB92iIK6WUNcZzRL4XuFdEzgE1wGYReQaoAFIZuZvl+JhvWZYYYyp8UKtSSqlr8Bjk7rtVHrvi5SfHPP6pVytSSik1Ibb6ZqdSSqmraZArpZTNaZArpZTNaZArpZTNyci1TD9uUKQZcE3y46lAixfLCTY6Pjem43NjOj6eWTlGecaYa36j0u9BPhUiUmmMybe6jkCl43NjOj43puPjWaCOkZ5aUUopm9MgV0opm7NbkD9vdQEBTsfnxnR8bkzHx7OAHCNbnSNXSil1NbsdkSullLqCBrlSStmcLYLcUwPoUCQi94nID92PV4vIxyJSJSLfdb8WcmMmImEi8v/czcCPish6HZvPiUiCiLwuIqdF5LCIrNLxuTb3vlQuIneLyBz3eFWLyP8a857/4X7tmIjcYmW9tghybtAAOtS4f8i288WLLs8BjwDzgK0iMofQHLMHgBmM9JJ9hJFx0bH53N8B5caYBcB/B36Ajs/1fIeRMQH4n8A/M7JfLRCRr4jIMuBrwBxGZof9P5ZU6Tae+cgDwWcNoEVkD/Cs1QVZ7J3RByIyi5GL1kfdz/cCdwArCb0xm8nnjcI/FpGlwGEdm8/8BjjnfpwMTEP3nauIyGxGxuFXQDgjzXO+4R6PV4A7gQ7gBWPMIHBARHJEJNYY021FzXY5Ir9uA+hQY0b8CjjqfumzsXG7wEighdyYGWP+wxjzCwAR+UtG2hLq2LgZY5zGmEYROQLsZCTYdXyu9hPgbxnpV5wKXDKf39531Ri5NTLyrxhL2OUvx2MD6BB25dgYYOgar4fEmIlInIj8lJF/Gt+Gjs1VjDErgK8AP0TH5wtE5JvAAWPMafdL4/35Gn3dEnYJ8tEG0FyrAXSI+2xs3DKBakJwzEQkFngf6ALy0bH5AhHZPnrh0hjznvtlHZ8v2gAUi8gpRq65PA2kj1l+1Ri5zQCa/FTjVewS5NdtAB3q3E2vI0RkvojEMXKhah+hOWZ/BfzRGPO3xpheHZurhANbAESkENiPjs8XGGNKjDHzjTELgT3AXwKH3Bc4w4GtjIzPG8BD7rtbbgM+cZ+GsoRdLnZe1QDa4noCzd8AvwDigH81xtS7L1yF2pitAm4VkTvHvPZn6NiMehrYJSJ/xchUrH8JJKDj48n3gJeAFOBnxphDACLyPnAWaMP9C9Iq+hV9pZSyObucWlFKKXUdGuRKKWVzGuRKKWVzGuRKKWVzGuRKKWVzGuRKKWVzGuRKKWVz/x8hWsv9Oy+ocgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = (0.2,150,0) # Initial state\n",
    "x_data = [state[0]] # Store initial data \n",
    "N_data = [state[1]]\n",
    "t_data = [state[2]]\n",
    "my_policy = []\n",
    "episode = [] # Initialize episode for saving S, A, R values as list of lists\n",
    "\n",
    "\n",
    "for i in range(11): #take (10 + 1) steps\n",
    "    old_state = state # Old state for storing into episode\n",
    "    action = random.randint(0,Number_of_possible_actions - 1) # randint is end-exclusive\n",
    "    state, reward  = transition(state, action) # Evolve to get new state \n",
    "    episode += [[old_state, action, reward]] # Update step\n",
    "        \n",
    "    my_policy += [action]\n",
    "    x_data += [state[0]]\n",
    "    N_data += [state[1]]\n",
    "    t_data += [state[2]]\n",
    "print('Current policy:', my_policy)\n",
    "print('Concentration of x:', x_data)\n",
    "print('Concentration of N:', N_data)\n",
    "print('')\n",
    "print('Episode:', episode)\n",
    "score = transition((x_data[-2], N_data[-2],t_data[-2]),0)[1]\n",
    "print('Score:', score)\n",
    "def plot(t_data, x_data, N_data):\n",
    "    plt.figure()\n",
    "    plt.plot(t_data, x_data, label = 'x')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(t_data, N_data, label = 'N')\n",
    "    plt.legend()\n",
    "    \n",
    "plot(t_data, x_data, N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_random_action(epsilon): # epsilon represents the probability of taking a random action\n",
    "    if np.random.uniform(0,1) < epsilon:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(Q_table, epsilon): \n",
    "    '''Generates an episode with the chosen action of each step having:\n",
    "    Probability of epsilon       ---> random action\n",
    "    Probability of (1 - epsilon) ---> greedy action (according to Q table)\n",
    "    '''\n",
    "    episode = []\n",
    "    state = (0.2,150,0) # Initial state\n",
    "    for i in range(11): #take (10 + 1) steps\n",
    "        old_state = state # Old state for storing into episode\n",
    "        if old_state not in Q_table.keys(): # If state has NOT been visited before\n",
    "#             print('Unvisited')\n",
    "            action = random.randint(0,Number_of_possible_actions - 1) # Choose random action\n",
    "        else:                               # If state has been visited before\n",
    "#             print('Visited')\n",
    "            if take_random_action(epsilon): # Take random action\n",
    "                action = random.randint(0,Number_of_possible_actions - 1)\n",
    "            else:                           # Else take greedy action\n",
    "                action = np.argmax(Q_table[old_state])\n",
    "        \n",
    "        state, reward  = transition(state, action) # Evolve to get new state \n",
    "        episode += [[old_state, action, reward]] # Update step\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_Q_table(episode, Q_table):\n",
    "    '''takes in an episode [[S0,A0,R1], [S1,A1,R2] .... ] --> a list of lists\n",
    "    and a Q table\n",
    "    and returns the updated Q table using incremental averaging\n",
    "    '''\n",
    "    Q_table['episode_count'] += 1 # Counter for num of episodes (for incremental average)\n",
    "    for step in reversed(range(11)): # Episode has 11 entries, and Q table is updated in reversed order\n",
    "        state, action, reward = episode[step]\n",
    "\n",
    "        if step == 10: # If terminal state i.e. t = 384\n",
    "            G = reward # Return = reward at terminal state\n",
    "        else:\n",
    "            G = reward + 0.9*G  # Return = reward + discounted return of the PREVIOUS state\n",
    "\n",
    "        if state not in Q_table.keys(): # If state has not been visited before\n",
    "#             print('Unvisited')\n",
    "            Q_table[state] = []         # Initialize state entry in Q table\n",
    "            for a in range(Number_of_possible_actions): # Iterate through all actions\n",
    "                if a == action: # If the action is indeed taken\n",
    "                    Q_table[state] += [G]\n",
    "                else:\n",
    "                    Q_table[state] += [-100000] # assign a default large negative value\n",
    "\n",
    "        else:                          # Else state has been visited before\n",
    "#             print('Visited')\n",
    "            for a in range(Number_of_possible_actions):\n",
    "                if Q_table[state][a] != -100000: # If this specific (s, a) has been updated before\n",
    "                    Q_table[state][a] = Q_table[state][a] + 1/Q_table['episode_count']*(G - Q_table[state][a]) #Incremental average update\n",
    "                elif Q_table[state][a] == -100000 and a == action: # If this state visited before but action not taken before\n",
    "                    Q_table[state][a] = G\n",
    "    return Q_table            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_q_table(Q_table, num_iterations):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    for j in range(num_iterations):\n",
    "        state = (0.2,150,0) # Initial state\n",
    "        try:\n",
    "            for i in range(10): #take ten steps\n",
    "                    action = np.argmax(Q_table[state])\n",
    "                    state = transition(state, action)[0]\n",
    "            score = 100*state[0] - state[1]\n",
    "            count += 1\n",
    "            total_score += score\n",
    "        except:\n",
    "            pass\n",
    "    return total_score/count\n",
    "# score_q_table(Q_table1, num_iterations = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The method in the cell below **works**\n",
    "Epsilon needs to be decayed gradually and exponentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table1 = {'episode_count': 0} # Initialize empty Q table as dictionary of list where INDEX corresponds to action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.99     # Initialize epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes ran:  10\n",
      "Current epsilon:  0.98901\n",
      "Average score over 5k episodes:  53.78625134264232\n",
      "Average error between current Q table and previous Q table:  0.0\n",
      "\n",
      "Episodes ran:  20\n",
      "Current epsilon:  0.98802099\n",
      "Average score over 5k episodes:  35.37873965626989\n",
      "Average error between current Q table and previous Q table:  54886.35685158646\n",
      "\n",
      "Episodes ran:  30\n",
      "Current epsilon:  0.98703296901\n",
      "Average score over 5k episodes:  56.8\n",
      "Average error between current Q table and previous Q table:  52807.23240934538\n",
      "\n",
      "Episodes ran:  40\n",
      "Current epsilon:  0.98604593604099\n",
      "Average score over 5k episodes:  74.22048663262241\n",
      "Average error between current Q table and previous Q table:  45005.063907330354\n",
      "\n",
      "Episodes ran:  50\n",
      "Current epsilon:  0.985059890104949\n",
      "Average score over 5k episodes:  57.36266666666667\n",
      "Average error between current Q table and previous Q table:  34622.01589513791\n",
      "\n",
      "Episodes ran:  60\n",
      "Current epsilon:  0.984074830214844\n",
      "Average score over 5k episodes:  8.01154401154401\n",
      "Average error between current Q table and previous Q table:  30816.80866176482\n",
      "\n",
      "Episodes ran:  70\n",
      "Current epsilon:  0.9830907553846291\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_list = []     # Store scores vs number of episodes run\n",
    "episode_list = []   # Store episodes at which scores are recorded\n",
    "avg_error_list = [] # Avg error every 100 episodes\n",
    "\n",
    "while True:\n",
    "    Q_table_old = copy.deepcopy(Q_table1) # Save old Q table for comparison\n",
    "\n",
    "    epsilon *= 0.999\n",
    "    \n",
    "    num_episodes = 10 # Number of episodes to run\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        episode1 = generate_episode(Q_table1, epsilon)\n",
    "        Q_table1 = Update_Q_table(episode1, Q_table1)\n",
    "    num_keys = len(Q_table_old)\n",
    "    total_error = 0\n",
    "    \n",
    "    for key in Q_table_old.keys(): # Calculate average error\n",
    "#         print(key)\n",
    "        try:\n",
    "            for j in range(Number_of_possible_actions):\n",
    "#                 print(abs(Q_table1[key][j] - Q_table_old[key][j]))\n",
    "                total_error += abs(Q_table1[key][j] - Q_table_old[key][j])\n",
    "        except:\n",
    "            pass\n",
    "    avg_error = total_error/num_keys\n",
    "    avg_error_list += [avg_error]\n",
    "    \n",
    "    print('Episodes ran: ', Q_table1['episode_count'])\n",
    "    print('Current epsilon: ', epsilon)\n",
    "    if Q_table1['episode_count'] in range(0, 300000, 10): # Score every x number of episodes\n",
    "        try:\n",
    "            score = score_q_table(Q_table1, num_iterations = 5000)\n",
    "            score_list += [score]\n",
    "            episode_list += [Q_table1['episode_count']]\n",
    "            print('Average score over 5k episodes: ', score)\n",
    "        except:\n",
    "            pass\n",
    "    print('Average error between current Q table and previous Q table: ', avg_error)\n",
    "    print('')\n",
    "    if epsilon <= 0.05:\n",
    "        break\n",
    "Done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.minorticks_on()\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.tick_params(which='major', length=10, width=1, direction='out')\n",
    "ax.tick_params(which='minor', length=4, width=1, direction='out')\n",
    "plot(episode_list,score_list, color = 'blue')\n",
    "legend(frameon =  0, fontsize = 20)\n",
    "ylabel('Score (5k runs)', fontsize = 20)\n",
    "xlabel('Episodes', fontsize = 20)\n",
    "xticks(fontsize = 20)\n",
    "yticks(fontsize = 20)\n",
    "show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.minorticks_on()\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.tick_params(which='major', length=10, width=1, direction='out')\n",
    "ax.tick_params(which='minor', length=4, width=1, direction='out')\n",
    "plot(episode_list,score_list, color = 'blue')\n",
    "plot(np.linspace(100,episode_list[-1],len(avg_error_list)), avg_error_list, color = 'blue')\n",
    "legend(frameon =  0, fontsize = 20)\n",
    "ylabel('Average error', fontsize = 20)\n",
    "xlabel('Episodes', fontsize = 20)\n",
    "xticks(fontsize = 20)\n",
    "yticks(fontsize = 20)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(100,episode_list[-1],len(avg_error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avg_error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method in cell below doesn't work well\n",
    "You cannot decay episilon in the subtractive fashion\n",
    "End result: average score of ~5 over 15k steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table = {'episode_count': 0} # Initialize empty Q table as dictionary of list where INDEX corresponds to action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "epsilon = 0.90  \n",
    "\n",
    "# while True:\n",
    "#     epsilon -= 0.05\n",
    "#     print('Epsilon:',epsilon)\n",
    "#     num_episodes = 100000 # Number of episodes to run\n",
    "#     for i in range(num_episodes):\n",
    "#         episode = generate_episode(Q_table, epsilon)\n",
    "#         Q_table = Update_Q_table(episode, Q_table)\n",
    "#     print('Average score over 15k episodes:', score_q_table(Q_table, num_iterations = 15000))    \n",
    "#     if epsilon <= 0.05:\n",
    "#         break\n",
    "# Done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Number_of_possible_actions): # Test 2nd last step actions\n",
    "    total_score = 0\n",
    "    for j in range(1000):\n",
    "        new_state = transition( (1.2, 100.0, 345.6),i)\n",
    "        score = 100*new_state[0][0] - new_state[0][1]\n",
    "        total_score += score\n",
    "    print('action: ',i,'avg score: ', total_score/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Q table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = (0.2,150,0) # Initial state\n",
    "x_data = [state[0]] # Store initial data\n",
    "N_data = [state[1]]\n",
    "t_data = [state[2]]\n",
    "my_policy = []\n",
    "for i in range(10): #take ten steps\n",
    "        action = np.argmax(Q_table1[state])\n",
    "        state = transition(state, action)[0]\n",
    "        my_policy += [action]\n",
    "        x_data += [state[0]]\n",
    "        N_data += [state[1]]\n",
    "        t_data += [state[2]]\n",
    "print('Current policy:', my_policy)\n",
    "print('Concentration of x:', x_data)\n",
    "print('Concentration of N:', N_data)\n",
    "print('')\n",
    "score = 100*x_data[-1] - N_data[-1]\n",
    "print('Score:', score)\n",
    "def plot(t_data, x_data, N_data):\n",
    "    plt.figure()\n",
    "    plt.plot(t_data, x_data, label = 'x')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(t_data, N_data, label = 'N')\n",
    "    plt.legend()\n",
    "    \n",
    "plot(t_data, x_data, N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
