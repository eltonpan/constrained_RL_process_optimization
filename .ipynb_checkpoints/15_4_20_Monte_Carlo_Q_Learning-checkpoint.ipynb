{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sobol_seq in /opt/anaconda3/lib/python3.7/site-packages (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Authors: \n",
    "# E. Pan - Imperial College\n",
    "\n",
    "import pylab\n",
    "import numpy as np\n",
    "import scipy.integrate as scp\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import numpy.random as rnd\n",
    "from scipy.spatial.distance import cdist\n",
    "!pip install sobol_seq\n",
    "import sobol_seq\n",
    "from scipy.optimize import minimize\n",
    "eps  = np.finfo(float).eps\n",
    "import random\n",
    "import time\n",
    "matplotlib.rcParams['font.sans-serif'] = \"helvetica\"\n",
    "matplotlib.rcParams['font.family'] = \"helvetica\"\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from IPython.display import Audio, display # Import sound alert dependencies\n",
    "def Done():\n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "# Insert whatever audio file you want above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dyanmical System\n",
    "\n",
    "Here we have a dynamic system, where $x$ is biomas, $N$ is nitrogen source, and $F_{N_{in}}$ is an inflow rate.\n",
    "\n",
    "$$\\frac{\\text{d}x}{\\text{d}t}=\\mu~x~\\frac{N}{N+K_N}-\\mu_d~x$$\n",
    "\n",
    "$$\\frac{\\text{d}N}{\\text{d}t}=-Y_{Nx}x~\\mu~\\frac{N}{N+K_N}+F_{N_{in}}$$\n",
    "\n",
    "We wish to optimize at the final time $t_f$ the cost given by the biomass we can harves, minus a penalization for the nitrogen that was not consumed, the objective function is:\n",
    "\n",
    "$$f_{obj_1}=100x_{t_f}-N_{t_f}$$\n",
    "\n",
    "where $x_{t_f}$ and $N_{t_f}$ refer to the final biomass and nitrogen quantity. We can control $F_{N_{in}}\\in[0,7]$ with a precision of $0.5$ changing it $10$ times (equidistantly) from time $0$ to time $t_f$\n",
    "\n",
    "We can aditionally have an objective function that penalizes nitrogen source input:\n",
    "\n",
    "$$f_{obj_2}=100x_{t_f}-N_{t_f}-\\sum_{i=0}^{T}F_{N_{in}}^i$$\n",
    "\n",
    "where $T$ is the total number of time steps (inputs) and $F_{N_{in}}^i$ corresponds to the nitrate input at time-step $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming solutions\n",
    "\n",
    "To solve this problem, initially we should think of discretizing states (time is already discretized). This can be done for Biomass in $0.5$ intervals, and for Nitrate in $25$ intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Defining Environment ##############\n",
    "\n",
    "class Model_env: \n",
    "    \n",
    "    # --- initializing model --- #\n",
    "    def __init__(self, parameters, tf, modulus):\n",
    "        \n",
    "        # Object variable definitions\n",
    "        self.parameters       = parameters\n",
    "        self.tf, self.modulus = tf, modulus  # two column array [biomass nitrate]\n",
    "        \n",
    "    # --- dynamic model definition --- #    \n",
    "    # model takes state and action of previous time step and integrates -- definition of ODE system at time, t\n",
    "    def model(self, t, state):\n",
    "        # internal definitions\n",
    "        params = self.parameters\n",
    "        FCn   = self.u0\n",
    "                \n",
    "        # state vector\n",
    "        Cx  = state[0]\n",
    "        Cn  = state[1]\n",
    "        \n",
    "        # parameters\n",
    "        u_m  = params['u_m']; K_N  = params['K_N'];\n",
    "        u_d  = params['u_d']; Y_nx = params['Y_nx'];\n",
    "        \n",
    "        # algebraic equations\n",
    "        \n",
    "        # variable rate equations\n",
    "        dev_Cx  = u_m * Cx * Cn/(Cn+K_N) - u_d*Cx**2\n",
    "        dev_Cn  = - Y_nx * u_m * Cx * Cn/(Cn+K_N) + FCn\n",
    "        \n",
    "        return np.array([dev_Cx, dev_Cn],dtype='float64')\n",
    "    \n",
    "    def discrete_env(self, state):\n",
    "        # discretisation of the system, with introduction of stochasticity in terms of modulus\n",
    "        modulus = self.modulus\n",
    "        \n",
    "        # passing to arrays\n",
    "        modulus = np.array(modulus)    # eg. modulus = np.array([0.2, 20.]) basically what modulus does is it indicates the rounding of the conc of x and conc of nitrate\n",
    "        state   = np.array(state)  # eg. state = np.array([0.1,150.0]) first number is the conc of x and 2nd number is the conc of nitrate\n",
    "\n",
    "        resid = state % modulus \n",
    "        resid = resid/modulus # remember resid is now an array. resid is normalized with respect to the size of modulus \n",
    "        LB = resid.copy()\n",
    "        UB = 1 - resid # 1 minus resid because we are talking about normalized inverse length\n",
    "        draw = [0,0]\n",
    "        for i in range(state.shape[0]):\n",
    "            if LB[i] < UB[i]: #if lower bound distance is smaller (more likely to round down)\n",
    "                LB[i] = LB[i]**3 #make distance even closer\n",
    "                draw[i] = np.random.uniform(0,LB[i]+UB[i],1)\n",
    "            elif LB[i] > UB[i]: # else upper bound distance is smaller (more liekly to round up)\n",
    "                UB[i] = UB[i]**3\n",
    "                draw[i] = np.random.uniform(0,LB[i]+UB[i],1)\n",
    "            else:\n",
    "                draw[i] = np.random.uniform(0,1,1)        \n",
    "        for i in range(state.shape[0]):\n",
    "            if draw[i] < UB[i]: #introduce stochasticity w.r.t. rounding up or down\n",
    "                state[i] = state[i] - resid[i] * modulus[i] #rmb now resid is now a NORMALIZED array of 2 numbers so it has to be multiplied back to un-normalize residual #rounds down by substracting away the residual\n",
    "            else:\n",
    "                state[i] = state[i] - resid[i] * modulus[i] + modulus[i] #rounds up\n",
    "        \n",
    "        # fixes for representation \n",
    "        # Nitrate fix\n",
    "        if state[1] < 0:\n",
    "            state[1] = 0\n",
    "        elif state[0] < 0:\n",
    "            state[0] = 0\n",
    "        \n",
    "        # Biomass fix\n",
    "        f = str(self.modulus[0])\n",
    "        decimal = f[::-1].find('.')  \n",
    "        state[0] = np.round(state[0], decimal)\n",
    "        f1 = str(self.modulus[1])\n",
    "        decimal1 = f1[::-1].find('.')  \n",
    "        state[0] = np.round(state[0], decimal1)\n",
    "\n",
    "        if state[0] == eps:\n",
    "            state[0] = 0\n",
    "        if state[1] == eps:\n",
    "            state[1] = 0\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def simulation(self, x0, controls):\n",
    "        # internal definitions\n",
    "        model, tf     = self.model, self.tf\n",
    "        self.controls = controls\n",
    "        \n",
    "        # initialize simulation\n",
    "        current_state = x0\n",
    "        \n",
    "        # simulation #ONLY ONE STEP unlike the previous code shown above\n",
    "        self.u0   = controls[:]                       # control for this step\n",
    "        ode       = scp.ode(model)                      # define ode\n",
    "        ode.set_integrator('lsoda', nsteps=3000)        # define integrator\n",
    "        ode.set_initial_value(current_state, tf)         # set initial value\n",
    "        current_state = list(ode.integrate(ode.t + tf)) # integrate system\n",
    "        xt            = current_state                   # add current state Note: here we can add randomnes as: + RandomNormal noise\n",
    "        \n",
    "        return xt\n",
    "\n",
    "    def MDP_simulation(self, x0, controls): #simulate ONLY ONE STEP\n",
    "        xt          = self.simulation(x0, controls) #simulate\n",
    "        xt_discrete = self.discrete_env(xt) # make output state discrete\n",
    "        return xt_discrete\n",
    "\n",
    "    def reward(self, state):\n",
    "        reward = 100*state[-1][0] - state[-1][1]              # objective function 1\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating one Step of the dynamic system as a MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "# p        = {'u_m' : 0.0923*0.62, 'K_N' : 393.10, 'u_d' : 0.01, 'Y_nx' : 504.49} # predetermined parameters by design\n",
    "# tf       = 16.*24./10. # assuming 10 steps, we divide the whole horizon over 10 for one step\n",
    "# x0       = np.array([0.2,700.0]) # initial state\n",
    "# modulus  = [0.1, 60.] # basically what modulus does is it indicates the rounding of the conc of x and conc of nitrate\n",
    "# u0       = np.array([7.]) #this is your CONTROL (rmb here it's only ONE STEP)\n",
    "\n",
    "# MDP_BioEnv = Model_env(p, tf, modulus)\n",
    "# MDP_BioEnv.MDP_simulation(x0, u0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating multiple steps of the dynamic system as a MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modulus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4d1de4feb403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFCn_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mMDP_BioEnv\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mModel_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodulus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mu0\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFCn_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx0\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mMDP_BioEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMDP_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#simulate one step, and update current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modulus' is not defined"
     ]
    }
   ],
   "source": [
    "steps_      = 10\n",
    "FCn_0       = [np.sin(i/6.5)*2+5. for i in range(steps_)]\n",
    "x0          = np.array([0.2,150]) # initial state\n",
    "tf          = 16.*24./10.\n",
    "x_list      = np.zeros((2,steps_+1)) #initialize state as 2D array where the 2 rows refer to conc of x and N.\n",
    "t_list      = np.zeros((1,steps_+1)) #initialize time as 1D array\n",
    "x_list[:,0] = x0\n",
    "t_list[0]   = tf\n",
    "\n",
    "for s in range(len(FCn_0)):\n",
    "    MDP_BioEnv    = Model_env(p, tf, modulus)\n",
    "    u0            = np.array([FCn_0[s]])\n",
    "    x0            = MDP_BioEnv.MDP_simulation(x0, u0) #simulate one step, and update current state \n",
    "    tf            = tf + 16.*24./10. #increment time\n",
    "    x_list[:,s+1] = x0 #update state memory\n",
    "    t_list[:,s+1] = tf #update time memory\n",
    "\n",
    "for i in range(x_list.shape[0]):\n",
    "    plt.plot(t_list[0,:],x_list[i,:])\n",
    "    plt.ylabel('state')\n",
    "    plt.xlabel('time')\n",
    "    plt.show()\n",
    "plt.step(t_list[0,:-1],FCn_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.2,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,\n",
       "          0. ,   0. ],\n",
       "       [150. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,\n",
       "          0. ,   0. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and describe system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discrete_states: 319\n",
      "Shape of value table: 29 x 11\n",
      "Number of possible actions: 8\n",
      "Number of possible times: 11\n"
     ]
    }
   ],
   "source": [
    "p        = {'u_m' : 0.0923*0.62, 'K_N' : 393.10, 'u_d' : 0.01, 'Y_nx' : 504.49} # predetermined parameters by design\n",
    "tf       = 16.*24./10. # assuming 10 steps, we divide the whole horizon over 10 for one step\n",
    "modulus  = [0.20, 25.] # basically what modulus does is it indicates the rounding of the conc of x and conc of nitrate\n",
    "\n",
    "Number_of_possible_x      = int(2.0/modulus[0]+1) #assumed max x value is 1.6\n",
    "Number_of_possible_N      = int(700/modulus[1]+1) #assumed max N value is 400\n",
    "Number_of_discrete_states = int(Number_of_possible_x * Number_of_possible_N)\n",
    "max_increase_N = 7 # Maximum increase in N per time step\n",
    "increment_N    = 1 # Spacing between increase in N\n",
    "Number_of_possible_actions = int(max_increase_N/increment_N + 1)\n",
    "Number_of_possible_times   = 11\n",
    "\n",
    "MDP_BioEnv = Model_env(p, tf, modulus) # Initialize system\n",
    "\n",
    "print('Number of discrete_states:', Number_of_discrete_states)\n",
    "print('Shape of value table:', Number_of_possible_N , 'x', Number_of_possible_x)\n",
    "print('Number of possible actions:', Number_of_possible_actions)\n",
    "print('Number of possible times:', Number_of_possible_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to map action to actual increase in N\n",
    "action_ID = [x for x in range(Number_of_possible_actions)]\n",
    "increase_in_N = [x for x in np.arange(0,max_increase_N+increment_N,increment_N)]\n",
    "action_ID_to_increase_in_N = dict(zip(action_ID,increase_in_N))\n",
    "action_ID_to_increase_in_N #this dictionary maps action id to actual action itself (increase in N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(state, action): # state can be described by tuple(x (algae conc), N (nitrate conc), time (in hours)), action can be described by FN âˆˆ[0,7]\n",
    "    '''arguments\n",
    "       state: (x, N, t) tuple \n",
    "       action: int (0-14)\n",
    "    \n",
    "       outputs \n",
    "       new state: (x, N, t) tuple\n",
    "       reward: int \n",
    "       '''\n",
    "    state = np.array(state) \n",
    "    action = [action_ID_to_increase_in_N[action]] #assign action according to dictionary defined above\n",
    "    \n",
    "    if (abs(state[2] - 16.*24.) < 0.1): #check if terminal state is reached\n",
    "        reward = (100 * state[0] - state[1])   #give reward when we LEAVE terminal state\n",
    "        state[2]      += 16.*24./10. #increment time\n",
    "        state_evolved = MDP_BioEnv.MDP_simulation(state[0:2], action) #evolve the system using ODE\n",
    "        state_evolved = [round(state_evolved[0],1),round(state_evolved[1],1)]\n",
    "        new_state = np.append(state_evolved,round(state[2],2)) # append time\n",
    "        \n",
    "    elif (state[2] > 16.*24.): #check if time is exceeded\n",
    "        new_state = state #loop back to itself\n",
    "        reward = 0 #and given zero reward    \n",
    "\n",
    "    else: #else evolve the system and assign zero reward\n",
    "        state[2]      += 16.*24./10. #increment time\n",
    "        state_evolved = MDP_BioEnv.MDP_simulation(state[0:2], action) #evolve the system using ODE\n",
    "        state_evolved = [round(state_evolved[0],1),round(state_evolved[1],1)]\n",
    "        new_state = np.append(state_evolved,round(state[2],2)) # append time\n",
    "        reward    = 0 # if terminal step not reached, reward = 0\n",
    "\n",
    "    return tuple(new_state), reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.4, 100.0, 38.4), 0)\n",
      "((0.4, 125.0, 38.4), 0)\n",
      "((0.4, 150.0, 38.4), 0)\n",
      "((0.4, 175.0, 38.4), 0)\n",
      "((0.4, 200.0, 38.4), 0)\n",
      "((0.4, 225.0, 38.4), 0)\n",
      "((0.4, 275.0, 38.4), 0)\n",
      "((0.4, 300.0, 38.4), 0)\n"
     ]
    }
   ],
   "source": [
    "# Test transition function\n",
    "for i in range(Number_of_possible_actions):\n",
    "    print(transition((0.2,150,0),i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate 1 episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current policy: [5, 0, 0, 1, 5, 3, 3, 2, 0, 1, 5]\n",
      "Concentration of x: [0.2, 0.4, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6]\n",
      "Concentration of N: [150, 250.0, 100.0, 25.0, 25.0, 100.0, 75.0, 75.0, 50.0, 25.0, 25.0, 100.0]\n",
      "\n",
      "Episode: [[(0.2, 150, 0), 5, 0], [(0.4, 250.0, 38.4), 0, 0], [(0.6, 100.0, 76.8), 0, 0], [(0.6, 25.0, 115.2), 1, 0], [(0.6, 25.0, 153.6), 5, 0], [(0.6, 100.0, 192.0), 3, 0], [(0.6, 75.0, 230.4), 3, 0], [(0.6, 75.0, 268.8), 2, 0], [(0.6, 50.0, 307.2), 0, 0], [(0.6, 25.0, 345.6), 1, 0], [(0.6, 25.0, 384.0), 5, 35.0]]\n",
      "Score: 35.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = (0.2,150,0) # Initial state\n",
    "x_data = [state[0]] # Store initial data \n",
    "N_data = [state[1]]\n",
    "t_data = [state[2]]\n",
    "my_policy = []\n",
    "episode = [] # Initialize episode for saving S, A, R values as list of lists\n",
    "\n",
    "\n",
    "for i in range(11): #take (10 + 1) steps\n",
    "    old_state = state # Old state for storing into episode\n",
    "    action = random.randint(0,Number_of_possible_actions - 1) # randint is end-exclusive\n",
    "    state, reward  = transition(state, action) # Evolve to get new state \n",
    "    episode += [[old_state, action, reward]] # Update step\n",
    "        \n",
    "    my_policy += [action]\n",
    "    x_data += [state[0]]\n",
    "    N_data += [state[1]]\n",
    "    t_data += [state[2]]\n",
    "print('Current policy:', my_policy)\n",
    "print('Concentration of x:', x_data)\n",
    "print('Concentration of N:', N_data)\n",
    "print('')\n",
    "print('Episode:', episode)\n",
    "score = transition((x_data[-2], N_data[-2],t_data[-2]),0)[1]\n",
    "print('Score:', score)\n",
    "def plot(t_data, x_data, N_data):\n",
    "    plt.figure()\n",
    "    plt.plot(t_data, x_data, label = 'x')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(t_data, N_data, label = 'N')\n",
    "    plt.legend()\n",
    "    \n",
    "plot(t_data, x_data, N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_random_action(epsilon): # epsilon represents the probability of taking a random action\n",
    "    if np.random.uniform(0,1) < epsilon:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(Q_table, epsilon): \n",
    "    '''Generates an episode with the chosen action of each step having:\n",
    "    Probability of epsilon       ---> random action\n",
    "    Probability of (1 - epsilon) ---> greedy action (according to Q table)\n",
    "    '''\n",
    "    episode = []\n",
    "    state = (0.2,150,0) # Initial state\n",
    "    for i in range(11): #take (10 + 1) steps\n",
    "        old_state = state # Old state for storing into episode\n",
    "        if old_state not in Q_table.keys(): # If state has NOT been visited before\n",
    "#             print('Unvisited')\n",
    "            action = random.randint(0,Number_of_possible_actions - 1) # Choose random action\n",
    "        else:                               # If state has been visited before\n",
    "#             print('Visited')\n",
    "            if take_random_action(epsilon): # Take random action\n",
    "                action = random.randint(0,Number_of_possible_actions - 1)\n",
    "            else:                           # Else take greedy action\n",
    "                action = np.argmax(Q_table[old_state])\n",
    "        \n",
    "        state, reward  = transition(state, action) # Evolve to get new state \n",
    "        episode += [[old_state, action, reward]] # Update step\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_Q_table(episode, Q_table):\n",
    "    '''takes in an episode [[S0,A0,R1], [S1,A1,R2] .... ] --> a list of lists\n",
    "    and a Q table\n",
    "    and returns the updated Q table using incremental averaging\n",
    "    '''\n",
    "    Q_table['episode_count'] += 1 # Counter for num of episodes (for incremental average)\n",
    "    for step in reversed(range(11)): # Episode has 11 entries, and Q table is updated in reversed order\n",
    "        state, action, reward = episode[step]\n",
    "\n",
    "        if step == 10: # If terminal state i.e. t = 384\n",
    "            G = reward # Return = reward at terminal state\n",
    "        else:\n",
    "            G = reward + 0.9*G  # Return = reward + discounted return of the PREVIOUS state\n",
    "\n",
    "        if state not in Q_table.keys(): # If state has not been visited before\n",
    "#             print('Unvisited')\n",
    "            Q_table[state] = []         # Initialize state entry in Q table\n",
    "            for a in range(Number_of_possible_actions): # Iterate through all actions\n",
    "                if a == action: # If the action is indeed taken\n",
    "                    Q_table[state] += [G]\n",
    "                else:\n",
    "                    Q_table[state] += [-100000] # assign a default large negative value\n",
    "\n",
    "        else:                          # Else state has been visited before\n",
    "#             print('Visited')\n",
    "            for a in range(Number_of_possible_actions):\n",
    "                if Q_table[state][a] != -100000: # If this specific (s, a) has been updated before\n",
    "                    Q_table[state][a] = Q_table[state][a] + 1/Q_table['episode_count']*(G - Q_table[state][a]) #Incremental average update\n",
    "                elif Q_table[state][a] == -100000 and a == action: # If this state visited before but action not taken before\n",
    "                    Q_table[state][a] = G\n",
    "    return Q_table            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_q_table(Q_table, num_iterations):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    for j in range(num_iterations):\n",
    "        state = (0.2,150,0) # Initial state\n",
    "        try:\n",
    "            for i in range(10): #take ten steps\n",
    "                    action = np.argmax(Q_table[state])\n",
    "                    state = transition(state, action)[0]\n",
    "            score = 100*state[0] - state[1]\n",
    "            count += 1\n",
    "            total_score += score\n",
    "        except:\n",
    "            pass\n",
    "    return total_score/count\n",
    "# score_q_table(Q_table1, num_iterations = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The method in the cell below **works**\n",
    "Epsilon needs to be decayed gradually and exponentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table1 = {'episode_count': 0} # Initialize empty Q table as dictionary of list where INDEX corresponds to action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.99     # Initialize epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "score_list = []     # Store scores vs number of episodes run\n",
    "episode_list = []   # Store episodes at which scores are recorded\n",
    "avg_error_list = [] # Avg error every 100 episodes\n",
    "\n",
    "while True:\n",
    "    Q_table_old = copy.deepcopy(Q_table1) # Save old Q table for comparison\n",
    "\n",
    "    epsilon *= 0.999\n",
    "    \n",
    "    num_episodes = 10 # Number of episodes to run\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        episode1 = generate_episode(Q_table1, epsilon)\n",
    "        Q_table1 = Update_Q_table(episode1, Q_table1)\n",
    "    num_keys = len(Q_table_old)\n",
    "    total_error = 0\n",
    "    \n",
    "    for key in Q_table_old.keys(): # Calculate average error\n",
    "#         print(key)\n",
    "        try:\n",
    "            for j in range(Number_of_possible_actions):\n",
    "#                 print(abs(Q_table1[key][j] - Q_table_old[key][j]))\n",
    "                total_error += abs(Q_table1[key][j] - Q_table_old[key][j])\n",
    "        except:\n",
    "            pass\n",
    "    avg_error = total_error/num_keys\n",
    "    avg_error_list += [avg_error]\n",
    "    \n",
    "    print('Episodes ran: ', Q_table1['episode_count'])\n",
    "    print('Current epsilon: ', epsilon)\n",
    "    if Q_table1['episode_count'] in range(0, 300000, 10): # Score every x number of episodes\n",
    "        try:\n",
    "            score = score_q_table(Q_table1, num_iterations = 5000)\n",
    "            score_list += [score]\n",
    "            episode_list += [Q_table1['episode_count']]\n",
    "            print('Average score over 5k episodes: ', score)\n",
    "        except:\n",
    "            pass\n",
    "    print('Average error between current Q table and previous Q table: ', avg_error)\n",
    "    print('')\n",
    "    if epsilon <= 0.05:\n",
    "        break\n",
    "Done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.minorticks_on()\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.tick_params(which='major', length=10, width=1, direction='out')\n",
    "ax.tick_params(which='minor', length=4, width=1, direction='out')\n",
    "plot(episode_list,score_list, color = 'blue')\n",
    "legend(frameon =  0, fontsize = 20)\n",
    "ylabel('Score (5k runs)', fontsize = 20)\n",
    "xlabel('Episodes', fontsize = 20)\n",
    "xticks(fontsize = 20)\n",
    "yticks(fontsize = 20)\n",
    "show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.minorticks_on()\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.tick_params(which='major', length=10, width=1, direction='out')\n",
    "ax.tick_params(which='minor', length=4, width=1, direction='out')\n",
    "plot(episode_list,score_list, color = 'blue')\n",
    "plot(np.linspace(100,episode_list[-1],len(avg_error_list)), avg_error_list, color = 'blue')\n",
    "legend(frameon =  0, fontsize = 20)\n",
    "ylabel('Average error', fontsize = 20)\n",
    "xlabel('Episodes', fontsize = 20)\n",
    "xticks(fontsize = 20)\n",
    "yticks(fontsize = 20)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(100,episode_list[-1],len(avg_error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avg_error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method in cell below doesn't work well\n",
    "You cannot decay episilon in the subtractive fashion\n",
    "End result: average score of ~5 over 15k steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table = {'episode_count': 0} # Initialize empty Q table as dictionary of list where INDEX corresponds to action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "epsilon = 0.90  \n",
    "\n",
    "# while True:\n",
    "#     epsilon -= 0.05\n",
    "#     print('Epsilon:',epsilon)\n",
    "#     num_episodes = 100000 # Number of episodes to run\n",
    "#     for i in range(num_episodes):\n",
    "#         episode = generate_episode(Q_table, epsilon)\n",
    "#         Q_table = Update_Q_table(episode, Q_table)\n",
    "#     print('Average score over 15k episodes:', score_q_table(Q_table, num_iterations = 15000))    \n",
    "#     if epsilon <= 0.05:\n",
    "#         break\n",
    "# Done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Number_of_possible_actions): # Test 2nd last step actions\n",
    "    total_score = 0\n",
    "    for j in range(1000):\n",
    "        new_state = transition( (1.2, 100.0, 345.6),i)\n",
    "        score = 100*new_state[0][0] - new_state[0][1]\n",
    "        total_score += score\n",
    "    print('action: ',i,'avg score: ', total_score/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Q table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = (0.2,150,0) # Initial state\n",
    "x_data = [state[0]] # Store initial data\n",
    "N_data = [state[1]]\n",
    "t_data = [state[2]]\n",
    "my_policy = []\n",
    "for i in range(10): #take ten steps\n",
    "        action = np.argmax(Q_table1[state])\n",
    "        state = transition(state, action)[0]\n",
    "        my_policy += [action]\n",
    "        x_data += [state[0]]\n",
    "        N_data += [state[1]]\n",
    "        t_data += [state[2]]\n",
    "print('Current policy:', my_policy)\n",
    "print('Concentration of x:', x_data)\n",
    "print('Concentration of N:', N_data)\n",
    "print('')\n",
    "score = 100*x_data[-1] - N_data[-1]\n",
    "print('Score:', score)\n",
    "def plot(t_data, x_data, N_data):\n",
    "    plt.figure()\n",
    "    plt.plot(t_data, x_data, label = 'x')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(t_data, N_data, label = 'N')\n",
    "    plt.legend()\n",
    "    \n",
    "plot(t_data, x_data, N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
